{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84bff65f-13dc-4c6a-b3ad-44348a75f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import numpy as np\n",
    "import gudhi as gd\n",
    "import pickle\n",
    "import heapq\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4263ffda-1ab0-42e9-9117-b7619121c104",
   "metadata": {},
   "source": [
    "FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e692055-9541-4cbf-b563-eb64c0ef1aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load object file and extract the vertices and faces\n",
    "\n",
    "def load_obj_file(file_path):\n",
    "\n",
    "    mesh = trimesh.load(file_path)\n",
    "    \n",
    "    vertices = mesh.vertices\n",
    "    faces = mesh.faces\n",
    "    \n",
    "    return vertices, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8364f7d6-e6b3-4d28-9dd6-7816b1b540c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Farthest point sampling algorithm\n",
    "\n",
    "def farthest_point_sampling(points, num_samples):\n",
    "    \n",
    "    N, D = points.shape\n",
    "    sampled_indices = [np.random.randint(0, N)] \n",
    "    distances = np.full(N, np.inf)\n",
    "    \n",
    "    for _ in range(1, num_samples):\n",
    "        # Last sampled point\n",
    "        last_sampled_point = points[sampled_indices[-1]]\n",
    "        \n",
    "        # Euclidean distance to the last sampled point\n",
    "        dist_to_last_sampled = np.linalg.norm(points - last_sampled_point, axis=1)\n",
    "        \n",
    "        # Update minimum distances\n",
    "        distances = np.minimum(distances, dist_to_last_sampled)\n",
    "        \n",
    "        # Select the farthest point\n",
    "        next_sampled_index = np.argmax(distances)\n",
    "        sampled_indices.append(next_sampled_index)\n",
    "    \n",
    "    # Get sampled points\n",
    "    sampled_points = points[sampled_indices]\n",
    "    \n",
    "    return sampled_points, sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad91e10-e954-446d-ba6f-5288bef90253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize points \n",
    "\n",
    "def normalize_pc(points):\n",
    "\tcentroid = np.mean(points, axis=0)\n",
    "\tpoints -= centroid\n",
    "\tfurthest_distance = np.max(np.sqrt(np.sum(abs(points)**2,axis=-1)))\n",
    "\tpoints /= furthest_distance\n",
    "\n",
    "\treturn points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24d5d77a-c046-4739-9637-2d0c555eef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for k-nn algorithm\n",
    "\n",
    "def bottleneck_distance(diagram1,diagram2,h):\n",
    "    distance = gd.bottleneck_distance(diagram1.persistence_intervals_in_dimension(h),diagram2.persistence_intervals_in_dimension(h))\n",
    "    return distance\n",
    "\n",
    "def find_neighbors(X_train, query_point, k):\n",
    "    distances = []\n",
    "    \n",
    "    # Distance from the query point to each point in the training set\n",
    "    for i, data_point in enumerate(X_train):\n",
    "        distance = max(bottleneck_distance(query_point, data_point,0),bottleneck_distance(query_point, data_point,1),bottleneck_distance(query_point, data_point,2))\n",
    "        distances.append((i, distance))\n",
    "    \n",
    "    # Sorting distances in ascending order\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    \n",
    "    # Indices of the 'k' nearest neighbors\n",
    "    neighbors = [index for index, _ in distances[:k]]\n",
    "    return neighbors\n",
    "\n",
    "def predict(X_train, y_train, query_point, k): \n",
    "\n",
    "    neighbors = find_neighbors(X_train, query_point, k)\n",
    "    neighbor_labels = [y_train[i] for i in neighbors]\n",
    "    \n",
    "    # Count occurrences of each label among neighbors\n",
    "    label_counts = {}\n",
    "    for label in neighbor_labels:\n",
    "        if label in label_counts:\n",
    "            label_counts[label] += 1\n",
    "        else:\n",
    "            label_counts[label] = 1\n",
    "    \n",
    "    # Get the label with the highest count\n",
    "    predicted_class = max(label_counts, key=label_counts.get)\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a51fde-acb6-4c16-b539-3cf754847081",
   "metadata": {},
   "source": [
    "COMPUTATION OF PERSISTENCE DIAGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5cdf0a7-9de7-4b4d-9cf8-8d051fee48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD OBJECTS SAMPLED WITH EUCLIDIAN FPS\n",
    "\n",
    "objects = []\n",
    "y = []\n",
    "#n = 6\n",
    "animals = ['cat','elephant','face','head','horse']\n",
    "labels = ['cat','elephant','face','head','horse']\n",
    "#Abrir datos sampleados\n",
    "for animal in animals:\n",
    "    file_path = f'/home/andrea/Uni/Topological Data Analysis/Abusrz/{animal}_sampled.bin'\n",
    "\n",
    "    with open(file_path, 'rb') as file:\n",
    "    # Deserialize and retrieve the variable from the file\n",
    "        temp = pickle.load(file)\n",
    "        objects = objects + temp\n",
    "        y = y + [f'{animal}']*len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d58cb43-ee54-4ec3-a57d-38eca9ef557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#POINT CLOUD AND NORMALIZATION OF THE DATA\n",
    "\n",
    "point_clouds = []\n",
    "\n",
    "for i in range (0,len(objects)):\n",
    "    point_clouds.append(trimesh.points.PointCloud(objects[i][0]))\n",
    "\n",
    "\n",
    "for i in range (0,len(objects)):\n",
    "    normalize_pc(objects[i][0])\n",
    "\n",
    "for i in range (0,len(objects)):\n",
    "    point_clouds[i] = trimesh.points.PointCloud(objects[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1592759b-669c-42f3-95fd-64d877950bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PERSISTENCE DIAGRAMS \n",
    "\n",
    "VR = []\n",
    "STX = []\n",
    "diagX = []\n",
    "for i in range (0,len(objects)):\n",
    "    VR.append(gd.RipsComplex(points=point_clouds[i],sparse=True))\n",
    "    STX.append(VR[i].create_simplex_tree(max_dimension=2))\n",
    "    STX[i].collapse_edges(nb_iterations=3)\n",
    "    STX[i].expansion(3)\n",
    "    diagX.append(STX[i].persistence())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e129495a-99b6-439d-ba59-e876a11dc434",
   "metadata": {},
   "source": [
    "PREDICTIONS OF THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37af920d-49e1-4f95-9530-2ff94f4ad92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DICTIONARY OF LABELS\n",
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "labels = y\n",
    "\n",
    "grouped = defaultdict(list)\n",
    "\n",
    "for idx, label in enumerate(labels):\n",
    "    grouped[label].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f27f0591-fcfa-4c24-89ba-0dfe4346de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PICKING A RANDOM REPRESENTANT FOR EACH CLASS (1000 TIMES)\n",
    "\n",
    "\n",
    "random_indices = []\n",
    "X_test_list = []\n",
    "Y_test_list = []\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for i in range(1000):\n",
    "    # Picking a random index for each label\n",
    "    random_indices.append({label: random.choice(indices) for label, indices in grouped.items()})\n",
    "\n",
    "    X_train.append([STX[random_indices[i]['cat']],STX[random_indices[i]['elephant']],STX[random_indices[i]['face']],STX[random_indices[i]['head']],STX[random_indices[i]['horse']]])\n",
    "    Y_train.append([y[random_indices[i]['cat']],y[random_indices[i]['elephant']],y[random_indices[i]['face']],y[random_indices[i]['head']],y[random_indices[i]['horse']]])\n",
    "    \n",
    "    X_test = STX.copy()\n",
    "    Y_test = y.copy()\n",
    "\n",
    "    \n",
    "\n",
    "    # Indices to delete\n",
    "    indices_to_delete = [random_indices[i]['cat'],random_indices[i]['elephant'],random_indices[i]['face'],random_indices[i]['head'],random_indices[i]['horse']]\n",
    "\n",
    "    # Deleting elements starting from the highest index\n",
    "    for index in sorted(indices_to_delete, reverse=True):\n",
    "        X_test.pop(index)\n",
    "        Y_test.pop(index)\n",
    "        \n",
    "    X_test_list.append(X_test)\n",
    "    Y_test_list.append(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0db3482-20c5-478b-be2d-41a22e7ae464",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         Y_pred_list \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39mmap(predict_for_j, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_test_list)))\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Y_pred_list\n\u001b[0;32m---> 17\u001b[0m Y_pred_list \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m, in \u001b[0;36mparallel_prediction\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_prediction\u001b[39m():\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# 8 cores\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m multiprocessing\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 14\u001b[0m         Y_pred_list \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict_for_j\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Y_pred_list\n",
      "File \u001b[0;32m~/.config/jupyterlab-desktop/jlab_server/lib/python3.12/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.config/jupyterlab-desktop/jlab_server/lib/python3.12/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/.config/jupyterlab-desktop/jlab_server/lib/python3.12/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.config/jupyterlab-desktop/jlab_server/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/.config/jupyterlab-desktop/jlab_server/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#PREDICTIONS OF THE MODEL (1000 TIMES) WE USE MULTIPROCESSING LIBRARY TO PARALLELIZE THE COMPUTATIONS\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "def predict_for_j(j):\n",
    "    Y_pred_test = []\n",
    "    for i in range(len(Y_test_list[j])):\n",
    "        Y_pred_test.append(predict(X_train[j], Y_train[j], X_test_list[j][i], 1))\n",
    "    return Y_pred_test\n",
    "\n",
    "def parallel_prediction():\n",
    "    # 8 cores\n",
    "    with multiprocessing.Pool(processes=8) as pool:\n",
    "        Y_pred_list = pool.map(predict_for_j, range(len(X_test_list)))\n",
    "    return Y_pred_list\n",
    "\n",
    "Y_pred_list = parallel_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01c55be0-f03d-4e78-a474-d8813c17decd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_pred_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#ACCURACY\u001b[39;00m\n\u001b[1;32m      3\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mY_pred_list\u001b[49m)):\n\u001b[1;32m      5\u001b[0m     accuracy\u001b[38;5;241m.\u001b[39mappend(accuracy_score(Y_test_list[i], Y_pred_list[i]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_pred_list' is not defined"
     ]
    }
   ],
   "source": [
    "#ACCURACY\n",
    "\n",
    "accuracy = []\n",
    "for i in range(len(Y_pred_list)):\n",
    "    accuracy.append(accuracy_score(Y_test_list[i], Y_pred_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee21cad5-deed-4637-92f0-e4259a824ac6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/numpy/core/fromnumeric.py:2810\u001b[0m, in \u001b[0;36mmax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2692\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[1;32m   2693\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2695\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2696\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2697\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2698\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2808\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2811\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "np.max(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529a8a78-3504-45a3-8af6-57f3108d1ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ec021-0722-4ff9-abd5-e49b91aa2799",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9179e0ac-7767-4404-825a-6db84f36298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.index(np.max(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbcf222-8dc8-4255-a504-a47b5519b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_test_list[accuracy.index(np.max(accuracy))], Y_pred_list[accuracy.index(np.max(accuracy))])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Y_train[accuracy.index(np.max(accuracy))])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951b962c-610b-4b04-90ce-d7cef4c360fc",
   "metadata": {},
   "source": [
    "SAME PROCESS CONSIDERING P-ECCENTRICITY AND VORONOI MEASURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e54a56-b237-4405-a2ed-46177bb15a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distance matrices\n",
    "from scipy.spatial.distance import cdist\n",
    "distancias = []\n",
    "for i in range (0,len(objects)):\n",
    "    temp = cdist(point_clouds[i].vertices, point_clouds[i].vertices)\n",
    "    distancias.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf747833-2a34-4c63-85c5-e80f6e0d47cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set all distances to infinity\n",
    "distancias_vor = np.copy(distancias)\n",
    "for i in range (0,len(distancias)):\n",
    "    for j in range (0,len(distancias[i])):\n",
    "        distancias_vor[i][j,j]=np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe132f0-28ca-4aaf-8598-6cd18a1122cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voronoi weights\n",
    "pesos_voronoi = [] \n",
    "for k in range (0,len(distancias_vor)):\n",
    "    voronoi_temp = []\n",
    "    for i in range (0,len(distancias_vor[k])):\n",
    "        cont = 0\n",
    "        for j in range (0,len(distancias_vor[k])):\n",
    "            if distancias_vor[k][i,j] <= np.min(distancias_vor[k][j]):\n",
    "                cont+=1\n",
    "        voronoi_temp.append(cont)\n",
    "    pesos_voronoi.append(voronoi_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184404ab-e024-4cad-a14c-d53f3a946d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,len(pesos_voronoi)):\n",
    "    pesos_voronoi[i] = [j+1 for j in pesos_voronoi[i]]\n",
    "    pesos_voronoi[i] = [j/len(pesos_voronoi[i]) for j in pesos_voronoi[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc64038-aded-43e6-b76b-260a2eb358aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#P-ECCENTRICITY FORMULA\n",
    "\n",
    "p = 2\n",
    "lamb = 0.1\n",
    "\n",
    "for i in range (0,len(distancias)):\n",
    "    distancias[i] = distancias[i]**p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9ed66-a968-4699-9adc-dedd41374111",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "for i in range (0,len(distancias)):\n",
    "    s.append(distancias[i].dot(np.array(pesos_voronoi[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d69bdb-3935-4021-90a9-46ed3c930bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,len(s)):\n",
    "    s[i] = (s[i]**(1/p))*lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78c7d8-6099-43dc-8d9d-40353af17fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New simplices \n",
    "\n",
    "simplices = []\n",
    "for i in range (0,len(STX)):\n",
    "    simplices.append(list(STX[i].get_filtration()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc4b50-4e53-4a33-9911-92dd71e435ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "STXV = STX.copy()\n",
    "for k in range (0,len(STX)):\n",
    "    for i in range(len(simplices[k])):\n",
    "        p_excen=[s[k][j] for j in simplices[k][i][0]]\n",
    "        fil_val=[simplices[k][i][1]]\n",
    "        r=np.max(p_excen+fil_val)\n",
    "        STXV[k].assign_filtration(simplices[k][i][0],r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8150031a-b074-4268-89f9-c45afacd8c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN-TEST SETS (1000 TIMES)\n",
    "\n",
    "X_test_listV = []\n",
    "Y_test_listV = []\n",
    "X_trainV = []\n",
    "Y_trainV = []\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    X_trainV.append(STXV[random_indices[i]['cat']],STXV[random_indices[i]['elephant']],STXV[random_indices[i]['face']],STXV[random_indices[i]['head']],STXV[random_indices[i]['horse']]])\n",
    "    Y_trainV.append(y[random_indices[i]['cat']],y[random_indices[i]['elephant']],y[random_indices[i]['face']],y[random_indices[i]['head']],y[random_indices[i]['horse']]])\n",
    "    \n",
    "    X_test = STXV.copy()\n",
    "    Y_test = y.copy()\n",
    "\n",
    "    \n",
    "\n",
    "    # Indices to delete\n",
    "    indices_to_delete = [random_indices[i]['cat'],random_indices[i]['elephant'],random_indices[i]['face'],random_indices[i]['head'],random_indices[i]['horse']]\n",
    "\n",
    "    # Deleting elements starting from the highest index\n",
    "    for index in sorted(indices_to_delete, reverse=True):\n",
    "        X_test.pop(index)\n",
    "        Y_test.pop(index)\n",
    "        \n",
    "    X_test_listV.append(X_test)\n",
    "    Y_test_listV.append(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2995ccc-2992-49c3-b4a2-1474aa15defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICTIONS OF THE MODEL (1000 TIMES)\n",
    "\n",
    "def predict_for_j(j):\n",
    "    Y_pred_test = []\n",
    "    for i in range(len(Y_test_listV[j])):\n",
    "        Y_pred_test.append(predict(X_trainV[j], Y_trainV[j], X_test_listV[j][i], 1))\n",
    "    return Y_pred_test\n",
    "\n",
    "def parallel_prediction():\n",
    "    with multiprocessing.Pool(processes=8) as pool:\n",
    "        Y_pred_listV = pool.map(predict_for_j, range(len(X_test_listV)))\n",
    "    return Y_pred_listV\n",
    "\n",
    "Y_pred_listV = parallel_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6197ea62-139c-4454-b94c-8a0c6b0eccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACCURACY \n",
    "\n",
    "accuracyV = []\n",
    "for i in range(len(Y_pred_listV)):\n",
    "    accuracyV.append(accuracy_score(Y_test_listV[i], Y_pred_listV[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96be3afb-ff4a-4527-98dd-f759f618d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(accuracyV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bc290e-d8e6-464d-a752-eedd150ab1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(accuracyV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b101214-8abd-454c-9106-052e270bdef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(accuracyV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4030d18f-77ff-4744-ab61-9fef02eff95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_test_listbis[accuracyV.index(np.max(accuracyV))], Y_pred_listbis[accuracyV.index(np.max(accuracyV))])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Y_train[accuracyV.index(np.max(accuracyV))])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
